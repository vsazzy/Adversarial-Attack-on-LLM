{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvDtBboLkHL7"
      },
      "source": [
        "# Adversarial Attack on Cyberharassment Models\n",
        "\n",
        "In lab 3 (Adversarial attack on cyberharassment models), you will add noise to the input of a cyberharassment model to make the model misclassify the input. This lab will walk you through this and will develop your intuition about adversarial attacks in AI models.\n",
        "\n",
        "**You will learn:**\n",
        "- How adversarial attack is generally structured\n",
        "- How to attack an existing model\n",
        "- Adversarial attack algorithms\n",
        "- How to create a custom dataset loader in PyTorch and how to use a simple API that will do the same\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ehoe18ckedt"
      },
      "source": [
        "## Required modules\n",
        "First, run the cells below to import important packages needed for this lab. The second cell mounts Google drive which is where some files required for the lab will be stored. You will be prompted for authentication, please follow the instruction to authenticate.\n",
        "- [numpy](https://www.numpy.org/) a Python package for scientific computing.\n",
        "- [matplotlib](http://matplotlib.org) a Python library for visualization\n",
        "- [PIL](http://www.pythonware.com/products/pil/) a Python package for image processing\n",
        "- [torch](https://pytorch.org/) a Python open source source framework for deep learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qRXFJevgjeTa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.io import read_image\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Set a seed for unified output\n",
        "seed_val = 42\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3yGMuB32MBa"
      },
      "source": [
        "## Lab Overview\n",
        "\n",
        "You are given a model that have been trained (pretrained) to detect not safe for work (NSFW) images. You are\n",
        "also given a set pf NSFW test images. Of course building such models are important but as you will see in the\n",
        "lab, such a model can be fooled to not detect such contents.\n",
        "\n",
        "You will use adversarial algorithms to generate noise that will be added to the test images. When this modified\n",
        "test image is passed through the model, the model will classify it as not NSFW even though it is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvxBEgOS6mhP"
      },
      "source": [
        "## Data\n",
        "\n",
        "We will use some NSFW images obtained by downloading images using the [ nsfw_data_scrapper](https://github.com/EBazarov/nsfw_data_source_urls). Each image belong to 1 of 5 categories (neutral, hentai, drawings, porn and sexy). Each of the categories will be a folder containing images that belong to that category.\n",
        "\n",
        "Let us explore the test dataset. Download the data by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3DHnXUQ4URB1",
        "outputId": "40d0967b-0337-4f07-85a8-e6f3217519be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-28 05:34:36--  https://buffalo.box.com/shared/static/x1wqhcvq46ux4uwlzd3df3uy1qh1n87h.zip\n",
            "Resolving buffalo.box.com (buffalo.box.com)... 74.112.186.157, 2620:117:bff0:12d::\n",
            "Connecting to buffalo.box.com (buffalo.box.com)|74.112.186.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/x1wqhcvq46ux4uwlzd3df3uy1qh1n87h.zip [following]\n",
            "--2025-10-28 05:34:36--  https://buffalo.box.com/public/static/x1wqhcvq46ux4uwlzd3df3uy1qh1n87h.zip\n",
            "Reusing existing connection to buffalo.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://buffalo.app.box.com/public/static/x1wqhcvq46ux4uwlzd3df3uy1qh1n87h.zip [following]\n",
            "--2025-10-28 05:34:37--  https://buffalo.app.box.com/public/static/x1wqhcvq46ux4uwlzd3df3uy1qh1n87h.zip\n",
            "Resolving buffalo.app.box.com (buffalo.app.box.com)... 74.112.186.157, 2620:117:bff0:12d::\n",
            "Connecting to buffalo.app.box.com (buffalo.app.box.com)|74.112.186.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!c6FSBjACcXXgKSpgW1B7GAqRW2XPH8CtLBHJk0C0_-40XOYkC992AQ2UvxSpQjsvJG84HgarfkViv-lF1rrnCYCWB7eBxSHJrWUgm82kCbwSAVYklbff0wLQ4LzPdBDMbCLYbsomJf4v1b9_CQDWgawSv9AbXhjqxBfDIqbb_ysyZocpx2djbZNJ7Fz9WTi2rwWgda_EC3dOrZXMpbcqfulVNNLGDWk3-LVD-9LulNACkE97i8bLQhwWFiBGFEy3tWPWeEgY7Atdytt3vsUg1HYywN1tfeDOLHrk9gThO-JpC16k1N1ofrKUZZRHK2PSwZsepnmuBvOFktNKMxgQKZ8cu4wyvVbPRxPNhJ0BAv3v518AnBCKbHhp_2fa_ZBYVsey9WUteUGZQizk7RO6XiyMkLV_pL9onmH5oWX0gSjVlr8incVrtLZ89sHyjw_cpMy5LJ7KZELcKMj5N4v4AoLowQIibS5atz785RfDhbpHNrGxLA2RipstJRZ6R48o0xW0JBzh_et4Toc7sWq3aaaAxwDqRHWh5kcL6xFTjAbOrHbDwnwKmhpqaTqqwLrRSBJh92RkPs8qVN5QQGra4fH73m-ccu8EEVOL8eYmKw9zlb1hnZ0hcHkm96BMhgUv3xPoPNT_3hz4Erm_Yf88FBMuT6v8ym2b7QBPeMKHF2YB1HKwgweQiKfIx6CICjlW4yh_rLwmvZD0v7XdSYZMzTEDt-kcXYysQVcAatXDUEBsncZL3oLZTeLnFgV0_IbYSL9wjdfw_uX95CoccFcsqGvVQYjNBMnilGy-urFr5ltAT-0MfQ6fjNJ87QZ3O5PKRhpZIj2YbJifJqU99Uf1FsBD-yrY3n44WQ5eJ-8xW3sC63wP6j8lpNLeD4dkEOLaQnA1VRFlNZjEY8bLC3zYWkL3yjL0f7DE13gtXvY6CVcvS_TkALBK3trtjTD3auGnthmFRukGHj-ZrR_d4VPwWd1c8LJK-u531jj3QO-h4nQG3mEO6xwOQW5vXdBS3AD6UePGEWN97h0oakAmczAh0SpEmO3ENdCntxbhPpnI4GnSnXGs3tRb1ZT5TWA5xlgp2qZHInVe8IXfkuAzxJNy1l0XkxIQR3Uu1jq6jhvCxfrCnefKjTs3pCLIqaFGlGv3mLofifU8eL3ER40om32-jqYFRxRq9mfQoctPwbFiBg6h-37VsXtxzC6vwstVZJU0ZYMGjpmkDsPX7hSHlL-yBgW7xoDQ2ngOU_lE3yy8Y6_A9Q43_zOvxcPTbiveUsw_wM3e_IQFB_JhYMkoTfYufpGlsCm5_2ENRSv0Jr-BcnItqEsLtK0zDSuTelY1LwtvmOMlxZBifGN6jTP7scfpnR9fE35z6HqmrVVEr1jgNcB_BkkYTceuMO7KFCiJ4EitZ3dq0HbSN3qsPYZNWyGpPqTG3xZRAi0Lf5-zRiTonOMOtCCII8neFCnD3ASg2RkUJrG-keK7KaL1hjnou6eGZN3OIhE1KxQs5VoGmHZBoA../download [following]\n",
            "--2025-10-28 05:34:38--  https://public.boxcloud.com/d/1/b1!c6FSBjACcXXgKSpgW1B7GAqRW2XPH8CtLBHJk0C0_-40XOYkC992AQ2UvxSpQjsvJG84HgarfkViv-lF1rrnCYCWB7eBxSHJrWUgm82kCbwSAVYklbff0wLQ4LzPdBDMbCLYbsomJf4v1b9_CQDWgawSv9AbXhjqxBfDIqbb_ysyZocpx2djbZNJ7Fz9WTi2rwWgda_EC3dOrZXMpbcqfulVNNLGDWk3-LVD-9LulNACkE97i8bLQhwWFiBGFEy3tWPWeEgY7Atdytt3vsUg1HYywN1tfeDOLHrk9gThO-JpC16k1N1ofrKUZZRHK2PSwZsepnmuBvOFktNKMxgQKZ8cu4wyvVbPRxPNhJ0BAv3v518AnBCKbHhp_2fa_ZBYVsey9WUteUGZQizk7RO6XiyMkLV_pL9onmH5oWX0gSjVlr8incVrtLZ89sHyjw_cpMy5LJ7KZELcKMj5N4v4AoLowQIibS5atz785RfDhbpHNrGxLA2RipstJRZ6R48o0xW0JBzh_et4Toc7sWq3aaaAxwDqRHWh5kcL6xFTjAbOrHbDwnwKmhpqaTqqwLrRSBJh92RkPs8qVN5QQGra4fH73m-ccu8EEVOL8eYmKw9zlb1hnZ0hcHkm96BMhgUv3xPoPNT_3hz4Erm_Yf88FBMuT6v8ym2b7QBPeMKHF2YB1HKwgweQiKfIx6CICjlW4yh_rLwmvZD0v7XdSYZMzTEDt-kcXYysQVcAatXDUEBsncZL3oLZTeLnFgV0_IbYSL9wjdfw_uX95CoccFcsqGvVQYjNBMnilGy-urFr5ltAT-0MfQ6fjNJ87QZ3O5PKRhpZIj2YbJifJqU99Uf1FsBD-yrY3n44WQ5eJ-8xW3sC63wP6j8lpNLeD4dkEOLaQnA1VRFlNZjEY8bLC3zYWkL3yjL0f7DE13gtXvY6CVcvS_TkALBK3trtjTD3auGnthmFRukGHj-ZrR_d4VPwWd1c8LJK-u531jj3QO-h4nQG3mEO6xwOQW5vXdBS3AD6UePGEWN97h0oakAmczAh0SpEmO3ENdCntxbhPpnI4GnSnXGs3tRb1ZT5TWA5xlgp2qZHInVe8IXfkuAzxJNy1l0XkxIQR3Uu1jq6jhvCxfrCnefKjTs3pCLIqaFGlGv3mLofifU8eL3ER40om32-jqYFRxRq9mfQoctPwbFiBg6h-37VsXtxzC6vwstVZJU0ZYMGjpmkDsPX7hSHlL-yBgW7xoDQ2ngOU_lE3yy8Y6_A9Q43_zOvxcPTbiveUsw_wM3e_IQFB_JhYMkoTfYufpGlsCm5_2ENRSv0Jr-BcnItqEsLtK0zDSuTelY1LwtvmOMlxZBifGN6jTP7scfpnR9fE35z6HqmrVVEr1jgNcB_BkkYTceuMO7KFCiJ4EitZ3dq0HbSN3qsPYZNWyGpPqTG3xZRAi0Lf5-zRiTonOMOtCCII8neFCnD3ASg2RkUJrG-keK7KaL1hjnou6eGZN3OIhE1KxQs5VoGmHZBoA../download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 74.112.186.165, 2620:117:bff0:69::\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|74.112.186.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24608350 (23M) [application/zip]\n",
            "Saving to: ‘x1wqhcvq46ux4uwlzd3df3uy1qh1n87h.zip’\n",
            "\n",
            "x1wqhcvq46ux4uwlzd3 100%[===================>]  23.47M  10.9MB/s    in 2.2s    \n",
            "\n",
            "2025-10-28 05:34:40 (10.9 MB/s) - ‘x1wqhcvq46ux4uwlzd3df3uy1qh1n87h.zip’ saved [24608350/24608350]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "if not Path('test').is_dir():\n",
        "    !wget https://buffalo.box.com/shared/static/x1wqhcvq46ux4uwlzd3df3uy1qh1n87h.zip\n",
        "    # Unzip it\n",
        "    !unzip -q x1wqhcvq46ux4uwlzd3df3uy1qh1n87h.zip -d test/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHsZsDqg6bQm"
      },
      "source": [
        "Let us first use a custom dataset class to explore our dataset. After running the cell above, the category folders with the images were stored in a 'test' folder in your google drive. The code below retrieves an image from the category folders in 'test'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRC3N1UUk-mZ"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_directory, image_transform=None, label_transform=None):\n",
        "        \"\"\"\n",
        "        Generate a single example and its label from image_directory\n",
        "        Args:\n",
        "            image_directory (String): The parent directory containing the directory that the images reside\n",
        "            image_transform (NoneType): Transformation to apply to the image, defaults to None\n",
        "            label_transform (NoneType): Transformation to apply to the image labels, defaults to None\n",
        "        Retruns:\n",
        "            example (Tuple): A tuple of tensors - image and label\n",
        "        \"\"\"\n",
        "\n",
        "        if not os.path.exists(image_directory):\n",
        "            raise ValueError(f\"Input file {image_directory} does not exist\")\n",
        "\n",
        "        self.image_directory = image_directory\n",
        "        self.image_transform = image_transform\n",
        "        self.label_transform = label_transform\n",
        "        self.img_labels = []\n",
        "        self.classes = ['drawings', 'hentai', 'neutral', 'sexy']\n",
        "\n",
        "        for category in self.classes:\n",
        "            # if not os.path.exists(self.image_directory + '/' + category):\n",
        "            #       os.makedirs(self.image_directory + '/' + category)\n",
        "            files = os.listdir(self.image_directory + '/' + category)\n",
        "            # Create a list of (image name, class folder) tuples\n",
        "            self.img_labels.extend([(img_file, category) for img_file in files])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Read the image by getting its path: parent_directory/class/<name>.png\n",
        "        image_path = self.img_labels[index][1] + \"/\" + self.img_labels[index][0]\n",
        "        path = os.path.join(self.image_directory, image_path)\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        label = self.classes.index(self.img_labels[index][1])\n",
        "\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "        if self.label_transform:\n",
        "            label = self.label_transform(label)\n",
        "        example = (image, label)\n",
        "\n",
        "        return example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY_LhUVR8afq"
      },
      "source": [
        "View the image at index 0 (the drawings category)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs2KI2Lc84Hz"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/test\"\n",
        "test_data = CustomImageDataset(image_path,\n",
        "                               image_transform=None,\n",
        "                               label_transform=None)\n",
        "index = 13\n",
        "image, label = test_data[index]\n",
        "plt.imshow(image)\n",
        "print(f'class = {label}, which is {test_data.classes[label]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut5-YadJBLw5"
      },
      "source": [
        "\n",
        "***\n",
        "**<font color='red'>Task 1:</font>** Find the number of images there are in all category. <br> Don't access the attribute '\\_\\_len\\_\\_'. You can use the len function directly on the object of the CustomImageDataset class.\n",
        "***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpNr5LL48_MU"
      },
      "outputs": [],
      "source": [
        "# Start code here #\n",
        "total_number_of_images = None\n",
        "# End code here #\n",
        "\n",
        "print(f\"The number of images in the test dataset is: {total_number_of_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8hJdEk6DKwb"
      },
      "source": [
        "Now, use an built in PyTorch function to load the test dataset. We will use this built in function for the rest of this lab. Run the cells below to view an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I69dGN7TDjc5"
      },
      "outputs": [],
      "source": [
        "test_dataset = datasets.ImageFolder(image_path, transform=None)\n",
        "class_dict = test_dataset.class_to_idx\n",
        "print(f\"Category/class map: {class_dict}\")\n",
        "idx_to_class = {}\n",
        "for category, idx in class_dict.items():\n",
        "    idx_to_class[idx] = category\n",
        "\n",
        "index = 0\n",
        "image, label = test_dataset[index]\n",
        "plt.imshow(image)\n",
        "print(f'class = {label}, which is {idx_to_class[label]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRNT9hJQG_zh"
      },
      "source": [
        "It is important to keep the dimension of all images the same, this allows to group a batch of images with the same shape into a single matrix/vector. We will perform some transformations on each image, for each image we make it a specific height and weight (224 x 224), center it, convert it to a tensor (converting the pixels into a vector) and normalize it. In this lab, we will batch our images into groups of 1 i.e each image is in its own batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i2keCjrHM6U"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/test\"\n",
        "batch_size = 1\n",
        "test_image_transforms = transforms.Compose([transforms.Resize(224),\n",
        "                                            transforms.CenterCrop(224),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize(\n",
        "                                                mean=[0.485, 0.456, 0.406],\n",
        "                                                std=[0.229, 0.224, 0.225])\n",
        "                                        ])\n",
        "\n",
        "dataset = datasets.ImageFolder(image_path, transform=test_image_transforms)\n",
        "class_dict = dataset.class_to_idx\n",
        "index_to_class = {}\n",
        "for category, idx in class_dict.items():\n",
        "    index_to_class[idx] = category\n",
        "\n",
        "# Batch dataset and create an iterator over the dataset\n",
        "test_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB78mEWwK6Iu"
      },
      "source": [
        "***\n",
        "**<font color='red'>Task 2:</font>**\n",
        "- What is the size of an image and its label?\n",
        "- What is the label index?\n",
        "- What is the actual label (drawings, hentai, sexy, porn or neutral)?\n",
        "\n",
        "Each image should be of the shape (batch size, # channels, height, weight). You can use the size() function to get the shape of a tensor and you can use the item() function to retrieve the element of a tensor.\n",
        "\n",
        "Replace 'None' with the correct variable in the code below\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_dCcyX2J_3i"
      },
      "outputs": [],
      "source": [
        "classes =  list(class_dict.keys())\n",
        "print(f\"actual labels: {classes}\")\n",
        "\n",
        "# View one example\n",
        "# Start code here #\n",
        "for None, None in test_dataloader:\n",
        "    print(f\"label index is: {None}\")\n",
        "    image_size = None\n",
        "    label_size = None\n",
        "    label = None\n",
        "    break\n",
        "# End code here #\n",
        "\n",
        "print(f\"Image size: {image_size}, label size: {label_size} and class: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nyMgOD3j_iX"
      },
      "source": [
        "## White-box Attack\n",
        "\n",
        "In a white-box attack, the adversary (the agent generating the adversarial examples) have knowledge about the target model architecture, its parameters and training data. We will be performing a white-box attack since we have a model that have been trained to detect NSFW, we have access to its parameters and we know the data it was trained on.\n",
        "\n",
        "Define the model architecture by running the cell below. Notice that in the **get_model()** function below, the last layer has 10 neurons instead of 5 (the NSFW classes). We do not know the reason why the original authors maintained the number of classes in the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. Five would have been the natural number of neurons to use. However, observe that since the network have been trained on the NSFW dataset, the neuron with the highest probability will always be in the first five neurons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZo4_Fmak04y"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    \"\"\"\n",
        "    Initialize the NSFW model which is a modified ResNet50 model with\n",
        "    two additional fully-connected layers\n",
        "    Args:\n",
        "        None\n",
        "    Returns:\n",
        "        model (nn.Module): pre-trained NSFW model\n",
        "    \"\"\"\n",
        "\n",
        "    # NSFW model uses ResNet50 with additional layers\n",
        "    # Load ResNet50 model\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    number_of_fully_connected_features = model.fc.in_features\n",
        "\n",
        "    # Replacing last layer\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(number_of_fully_connected_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(512, 10),\n",
        "        nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7KHbXz2my3g"
      },
      "source": [
        "Download the model parameters (pre-trained weights) by running the cell below.\n",
        "We will make use of a pretrained NSFW [model](https://github.com/emiliantolo/pytorch_nsfw_model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1d5KCbbbvK3"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile('ResNet50_nsfw_model.pth'):\n",
        "    !wget https://github.com/emiliantolo/pytorch_nsfw_model/blob/master/ResNet50_nsfw_model.pth?raw=true -O ResNet50_nsfw_model.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8yELK7qnBKT"
      },
      "source": [
        "Initialize the model and load its parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEsOt5Ktnvq9"
      },
      "outputs": [],
      "source": [
        "# Use GPU if it is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pre_trained_model_path = \"/content/ResNet50_nsfw_model.pth\"\n",
        "# Initialize the network\n",
        "model = get_model().to(device)\n",
        "\n",
        "# Initialize the network with the pretrained weights (parameters that the previous model learned)\n",
        "model.load_state_dict(torch.load(pre_trained_model_path, map_location='cpu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2PSTiBiq8mq"
      },
      "source": [
        "## Attack\n",
        "We will use fast gradient sign method (FGSM) to generate adversarial perturbations to fool the target model into predicting the wrong output.\n",
        "\n",
        "Given an image $x$, FGSM generates an adversarial image $$x^{'} = x + ϵ * sign(∇_xJ(θ, x, l))$$\n",
        "\n",
        "***\n",
        "**<font color='red'>Task 3:</font>** Implement the FGSM formula in the code blow. Replace \"None\" with the formula.\n",
        "***\n",
        "\n",
        "Credit: The code in this section has been adapted from Nathan Inkawhich's work on adversarial example generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NNf5cXSr4Y3"
      },
      "outputs": [],
      "source": [
        "def fgsm(image, epsilon, data_grad):\n",
        "    \"\"\"\n",
        "    Perform the FGSM attack on a single image\n",
        "    Args:\n",
        "        image (torch.tensor): The image to be perturbed\n",
        "        epsilon (float): Hyperparameter for controlling the scale of perturbation\n",
        "        data_grad (): The gradient of the loss wrt to image\n",
        "    Returns:\n",
        "        perturbed_image (torch.tensor): a perturbed image\n",
        "    \"\"\"\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "\n",
        "    # Start code here ~ 1 line of code #\n",
        "    perturbed_image = None\n",
        "    # End code here #\n",
        "\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    if epsilon != 0.0:\n",
        "        perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNnQzVGCME0_"
      },
      "source": [
        "We will also use the projected gradient descent (PGD) method to generate adversarial examples.\n",
        "\n",
        "Given a vectorized image $x$, PGD generates an adversarial image by\n",
        "$$x^{'}_0 = x$$\n",
        "\n",
        "> Repeat:\n",
        " $$x^{'}_{N+1} = Clip_x,_\\epsilon \\{x^{'}_N + \\alpha * sign(∇_xJ(θ, x^{'}_N, l))\\}$$\n",
        "\n",
        "***\n",
        "**<font color='red'>Task 4:</font>** Implement the PGD formula in the code blow. Replace \"None\" with the formula.\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ic4ywCpX5MX"
      },
      "outputs": [],
      "source": [
        "def pgd(model, image, label, epsilon, alpha, iterations):\n",
        "    \"\"\"\n",
        "    Perform the PGD attack on an image\n",
        "    Args:\n",
        "        model (nn.Module): The NSFW model\n",
        "        image (tensor): The images to be perturbed of shape [# channels, height, weight]\n",
        "        label (tensor): The true labels of images of shape (1,)\n",
        "        epsilon (float): Hyperparameter for controlling the scale of perturbation\n",
        "        alpha (float): The step size i.e scale of the perturbation\n",
        "        iterations (int): The number of iterations of images\n",
        "    Returns:\n",
        "        result (Tuple): A tuple of the perturbed image and the initial prediction for visualization purposes\n",
        "    \"\"\"\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "    original_image = image\n",
        "\n",
        "    image.requires_grad = True\n",
        "    output = model(image)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "    if init_pred.item() != label.item():\n",
        "        return None, init_pred\n",
        "\n",
        "    for i in range(iterations) :\n",
        "        image.requires_grad = True\n",
        "        output = model(image)\n",
        "\n",
        "        model.zero_grad()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(output, label).to(device)\n",
        "        loss.backward()\n",
        "\n",
        "        sign_data_grad = image.grad.sign()\n",
        "\n",
        "        # Start code here ~ 1 line of code #\n",
        "        perturbed_image = None\n",
        "        # End code here #\n",
        "\n",
        "        # Perform clipping\n",
        "        eta = torch.clamp(perturbed_image - original_image, min = -epsilon, max = epsilon)\n",
        "        image = torch.clamp(original_image + eta, min = 0, max = 1).detach_()\n",
        "\n",
        "    return image, init_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR5lpaxrg57e"
      },
      "source": [
        "***\n",
        "**<font color='red'>Task 5:</font>**\n",
        "- Perform a forward pass through the model using the original image\n",
        "- Perform an FGSM attack by using fgsm(...) function to generate an adversarial image\n",
        "- Perform a forward pass through the model using the adversarial image\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0CcczuvtVg6"
      },
      "outputs": [],
      "source": [
        "def fgsm_attack(model, test_dataloader, epsilon):\n",
        "    \"\"\"\n",
        "    Performs the FGSM/PGD attack on a dataset given a specific epsilon value\n",
        "    Args:\n",
        "        model (nn.Module): The neural network under attack\n",
        "        device (): put variables into cpu/gpu mode\n",
        "        test_dataloader (DataLoader): an iterable over the dataset\n",
        "        epsilon (float): hyperparameter for controlling the scale of perturbation\n",
        "        attack_type (String): adversarial attack method, defaults to FGSM\n",
        "    Returns:\n",
        "        final_acc, adversarial_examples (Tuple): a tuple of the final accuracy\n",
        "        of the attack and some adversarial examples for visualization\n",
        "    \"\"\"\n",
        "\n",
        "    # We are not training, so set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adversarial_examples = []\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_dataloader:\n",
        "\n",
        "        # Send the data and label to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Forward pass the data through the model\n",
        "\n",
        "        # Start code here ~ 1 line of code #\n",
        "        output = None\n",
        "        # End code here #\n",
        "\n",
        "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "\n",
        "        # Calculate the loss\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Zero all existing gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Collect datagrad\n",
        "        data_grad = data.grad.data\n",
        "\n",
        "        # Call FGSM to add perturbation to the data\n",
        "\n",
        "        # Start code here ~ 1 line of code #\n",
        "        perturbed_data = None\n",
        "        # End code here #\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "\n",
        "        # Start code here ~ 1 line of code #\n",
        "        output = None\n",
        "        # End code here #\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0) and (len(adversarial_examples) < 5):\n",
        "                adversarial_example = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                if (init_pred.item() == 0 and final_pred.item() == 0) or \\\n",
        "                   (init_pred.item() == 2 and final_pred.item() == 2):\n",
        "                    adversarial_examples.append( (init_pred.item(), final_pred.item(), adversarial_example) )\n",
        "        else:\n",
        "            # Save some adversarial examples for visualization later\n",
        "            if len(adversarial_examples) < 5:\n",
        "                adversarial_example = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                if (init_pred.item() == 0 and final_pred.item() == 0) or \\\n",
        "                (init_pred.item() == 0 and final_pred.item() == 2) or \\\n",
        "                (init_pred.item() == 2 and final_pred.item() == 0) or \\\n",
        "                (init_pred.item() == 2 and final_pred.item() == 1):\n",
        "                    adversarial_examples.append( (init_pred.item(), final_pred.item(), adversarial_example) )\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct / float(len(test_dataloader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_dataloader), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adversarial_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41sicHKDhi1T"
      },
      "source": [
        "***\n",
        "**<font color='red'>Task 6:</font>**\n",
        "- Perform an PGD attack by using the pgd(...) function to generate an adversarial image\n",
        "- Perform a forward pass through the model using the adversarial image\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yE4JyuCX_Sxz"
      },
      "outputs": [],
      "source": [
        "def pgd_attack(model, test_dataloader, epsilon, alpha, iterations):\n",
        "    \"\"\"\n",
        "    Performs the PGD attack on a dataset given a specific epsilon value\n",
        "    Args:\n",
        "        model (nn.Module): The neural network under attack\n",
        "        device (): put variables into cpu/gpu mode\n",
        "        test_dataloader (DataLoader): an iterable over the dataset\n",
        "        epsilon (float): hyperparameter for controlling the scale of perturbation\n",
        "        attack_type (String): adversarial attack method, defaults to FGSM\n",
        "    Returns:\n",
        "        final_acc, adversarial_examples (Tuple): a tuple of the final accuracy\n",
        "        of the attack and some adversarial examples for visualization\n",
        "    \"\"\"\n",
        "\n",
        "    # We are not training, so set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adversarial_examples = []\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_dataloader:\n",
        "\n",
        "        # Call PGD to add perturbation to the data\n",
        "\n",
        "        # Start code here ~ 1 line #\n",
        "        perturbed_data, init_pred = None\n",
        "        # End code here #\n",
        "\n",
        "        if perturbed_data is None: # Don't replace this None\n",
        "            continue\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "\n",
        "        # Start code here ~ 1 line #\n",
        "        output = None\n",
        "        # End code here #\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0) and (len(adversarial_examples) < 5):\n",
        "                adversarial_example = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                if (init_pred.item() == 0 and final_pred.item() == 0) or \\\n",
        "                   (init_pred.item() == 2 and final_pred.item() == 2):\n",
        "                    adversarial_examples.append( (init_pred.item(), final_pred.item(), adversarial_example) )\n",
        "        else:\n",
        "            # Save some adversarial examples for visualization later\n",
        "            if len(adversarial_examples) < 5:\n",
        "                adversarial_example = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                if (init_pred.item() == 0 and final_pred.item() == 0) or \\\n",
        "                (init_pred.item() == 0 and final_pred.item() == 2) or \\\n",
        "                (init_pred.item() == 2 and final_pred.item() == 0) or \\\n",
        "                (init_pred.item() == 2 and final_pred.item() == 1):\n",
        "                    adversarial_examples.append( (init_pred.item(), final_pred.item(), adversarial_example) )\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct / float(len(test_dataloader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_dataloader), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adversarial_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K5YvkuAiBRc"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjkKMbum37qa"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy_vs_epsilon(epsilons, accuracies):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.plot(epsilons, accuracies, \"*-\")\n",
        "    plt.yticks(np.arange(0, 1.1, step=0.1))\n",
        "    plt.xticks(np.arange(0, .35, step=0.05))\n",
        "    plt.title(\"Accuracy vs Epsilon\")\n",
        "    plt.xlabel(\"Epsilon\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjkLnNEE4POK"
      },
      "outputs": [],
      "source": [
        "# Plot several examples of adversarial samples at each epsilon. Note: Only showing images from the drawings and neutral classes to avoid showing inappropriate content\n",
        "def plot_adversarial_samples(epsilons, adversarial_examples):\n",
        "    count = 0\n",
        "\n",
        "    plt.figure(figsize=(8,10))\n",
        "    for i in range(len(epsilons)):\n",
        "        for j in range(len(adversarial_examples[i])):\n",
        "            count += 1\n",
        "            plt.subplot(len(epsilons),len(adversarial_examples[0]), count)\n",
        "            plt.xticks([], [])\n",
        "            plt.yticks([], [])\n",
        "            if j == 0:\n",
        "                plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "            orig, adv, ex = adversarial_examples[i][j]\n",
        "            # Convert class indexes to string\n",
        "            orig = index_to_class[orig]\n",
        "            adv = index_to_class[adv]\n",
        "            plt.title(\"{}\\n -> {}\".format(orig, adv))\n",
        "            plt.imshow(np.transpose(ex, (1,2,0)), cmap=\"gray\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKG4zM8AuFxZ"
      },
      "source": [
        "## Execute FGSM Attack\n",
        "\n",
        "$ϵ$ controls the scale of the perturbations and we will use different $ϵ$ values to understand its effect.\n",
        "\n",
        "***\n",
        "**<font color='red'>Task 7:</font>**\n",
        "- Replace the 'None' in the code below with the correct variables and perform FGSM attack by running the cells below.\n",
        "- Describe your observations on the epsilons values\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gms4y6fMsp7I"
      },
      "outputs": [],
      "source": [
        "epsilons = [0.0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.14]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZrEFSVjuKW7"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "adversarial_examples = []\n",
        "\n",
        "# Perform attack using each epsilon value\n",
        "# Start code here #\n",
        "for None in epsilons:\n",
        "    accuracy, adversarial_example = None\n",
        "    accuracies.append(accuracy)\n",
        "    adversarial_examples.append(adversarial_example)\n",
        "# End code here #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdHJOABpkzi9"
      },
      "outputs": [],
      "source": [
        "# Visualize accuracy vs epsilon\n",
        "plot_accuracy_vs_epsilon(epsilons, accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8RQyILklXBC"
      },
      "outputs": [],
      "source": [
        "# Sample adversarial examples - Original prediction -> adversarial prediction\n",
        "plot_adversarial_samples(epsilons, adversarial_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5Mr52vVlkZC"
      },
      "source": [
        "## Execute PGD Attack\n",
        "\n",
        "$α$ determines how much we change the pixel values, we will use different $α$ values to understand its effect.\n",
        "\n",
        "***\n",
        "**<font color='red'>Task 8:</font>**\n",
        "- Replace the 'None' in the code below with the correct variables and perform PGD attack by completing and running the cells below. What are your observations?\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEHDbTsrBz2y"
      },
      "outputs": [],
      "source": [
        "epsilons = [0.0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.14]\n",
        "iterations = 2\n",
        "alpha = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBmENkrCG0rL"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "adversarial_examples = []\n",
        "\n",
        "# Perform attack using each epsilon value\n",
        "# Start code here #\n",
        "for None in epsilons:\n",
        "    accuracy, adversarial_example = None\n",
        "    accuracies.append(accuracy)\n",
        "    adversarial_examples.append(adversarial_example)\n",
        "# End code here #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfN3So-qkaj_"
      },
      "outputs": [],
      "source": [
        "# Visualize accuracy vs epsilon\n",
        "plot_accuracy_vs_epsilon(epsilons, accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L7DEH_ekjLj"
      },
      "outputs": [],
      "source": [
        "# Plot several examples of adversarial samples at each epsilon\n",
        "plot_adversarial_samples(epsilons, adversarial_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtIF5GOdX7rL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}